{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import nengo\n",
    "from nengo.solvers import LstsqL2, NoSolver\n",
    "from nengo.utils.matplotlib import rasterplot\n",
    "from nengo.utils.ensemble import tuning_curves\n",
    "from nengo.dists import Uniform\n",
    "from nengo.params import Default\n",
    "from nengo.utils.numpy import rmse\n",
    "\n",
    "from nengolib.signal import s, nrmse, LinearSystem\n",
    "from nengolib.synapses import Lowpass\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(context='poster', style='whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "from scipy.signal import convolve\n",
    "\n",
    "from nengo_bioneurons import BahlNeuron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_stimulus(signal, freq, amp, seed):       \n",
    "    if signal == 'cos':\n",
    "        return nengo.Node(output=lambda t: np.cos(freq*t))\n",
    "    elif signal == 'sin':\n",
    "        return nengo.Node(output=lambda t: np.sin(freq*t))\n",
    "    elif signal == 'white_noise':\n",
    "        return nengo.Node(nengo.processes.WhiteSignal(\n",
    "            period=100,\n",
    "            high=freq,\n",
    "            rms=amp,\n",
    "            seed=seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norms(signal, freq, amp, ss, tau, t, plot=False):\n",
    "    # first find the norm of the filtered signal\n",
    "    lpf=Lowpass(tau)\n",
    "    with nengo.Network() as model:\n",
    "        stim = make_stimulus(signal, freq, amp, ss)\n",
    "        p_stim = nengo.Probe(stim, synapse=None)\n",
    "        p_integral = nengo.Probe(stim, synapse=1/s)\n",
    "    with nengo.Simulator(model, progress_bar=False) as sim:\n",
    "        sim.run(t, progress_bar=False)\n",
    "    stimulus = sim.data[p_stim]\n",
    "    target = sim.data[p_integral]\n",
    "    target_f = lpf.filt(sim.data[p_integral])\n",
    "    norm_s = np.max(np.abs(stimulus))\n",
    "    norm = np.max(np.abs(target))\n",
    "    norm_f = np.max(np.abs(target_f))\n",
    "    \n",
    "    if plot:\n",
    "        plt.plot(sim.trange(), stimulus)\n",
    "        plt.plot(sim.trange(), target)\n",
    "        plt.plot(sim.trange(), lpf.filt(sim.data[p_integral]/norm_f))\n",
    "        plt.show()\n",
    "    return norm, norm_s, norm_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_activities_values_1d(\n",
    "    xhat_pre,\n",
    "    act_bio,\n",
    "    x_min=-1,\n",
    "    x_max=1,\n",
    "    n_neurons=10,\n",
    "    n_eval_points=20):\n",
    "\n",
    "    def find_nearest(array,value):\n",
    "        idx = (np.abs(array-value)).argmin()\n",
    "        return idx\n",
    "\n",
    "    x_bins = np.linspace(x_min, x_max, num=n_eval_points)\n",
    "    hz_means = np.empty((n_neurons, n_eval_points))\n",
    "    hz_stds = np.empty((n_neurons, n_eval_points))\n",
    "    for i in range(n_neurons):\n",
    "        bin_act = [[] for _ in range(x_bins.shape[0])]\n",
    "        for t in range(act_bio.shape[0]):\n",
    "            idx = find_nearest(x_bins, xhat_pre[t])\n",
    "            bin_act[idx].append(act_bio[t, i])\n",
    "        for x in range(len(bin_act)):\n",
    "            hz_means[i, x] = np.average(bin_act[x])\n",
    "            hz_stds[i, x] = np.std(bin_act[x])\n",
    "\n",
    "    return x_bins, hz_means, hz_stds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderNode(nengo.Node):\n",
    "    def __init__(\n",
    "            self,\n",
    "            conn,\n",
    "            n_bio,\n",
    "            n_syn,\n",
    "            dim,\n",
    "            d_pre,\n",
    "            eta,  # learning rate\n",
    "            seed, # learning seed\n",
    "            syn_encoders_init):\n",
    "        \n",
    "        self.conn = conn\n",
    "        self.n_syn = n_syn\n",
    "        self.dim = dim\n",
    "        self.d_pre = d_pre\n",
    "        self.eta = eta\n",
    "        self.rng = np.random.RandomState(seed=seed)\n",
    "        self.n_pre = self.d_pre.shape[0]\n",
    "        self.n_bio = n_bio\n",
    "        self.syn_encoders = syn_encoders_init\n",
    "        self.syn_weights = np.zeros_like(self.syn_encoders)\n",
    "        self.a_target = np.array([])\n",
    "        self.a_bio = np.array([])\n",
    "\n",
    "        super(EncoderNode, self).__init__(self.update, \n",
    "            size_in=2*self.n_bio,  # [a_bio, a_lif]\n",
    "            size_out=self.n_bio)\n",
    "\n",
    "    def update(self, t, x):\n",
    "        self.a_bio = x[0:self.n_bio]\n",
    "        self.a_target = x[self.n_bio:2*self.n_bio]\n",
    "        return self.a_bio - self.a_target\n",
    "    \n",
    "    def update_encoders(self, bio, pre, syn):\n",
    "        a_error = self.a_bio[bio] - self.a_target[bio]\n",
    "        d_syn = self.d_pre[pre]\n",
    "        e_old = self.syn_encoders[bio, pre, syn]\n",
    "        delta = self.rng.uniform(0, 2 * self.eta * np.abs(a_error))\n",
    "        if a_error > 0 and d_syn > 0:  # overactive, positive dec => reduce enc reduce weight\n",
    "            self.syn_encoders[bio, pre, syn] += -delta\n",
    "        if a_error > 0 and d_syn < 0:  # overactive, negative dec => increase enc reduce weight\n",
    "            self.syn_encoders[bio, pre, syn] += +delta\n",
    "        if a_error < 0 and d_syn > 0:  # underactive, positive dec => increase enc increase weight\n",
    "            self.syn_encoders[bio, pre, syn] += +delta\n",
    "        if a_error < 0 and d_syn < 0:  # underactive, negative dec => reduce enc increase weight\n",
    "            self.syn_encoders[bio, pre, syn] += -delta\n",
    "        w_new = np.dot(d_syn, self.syn_encoders[bio, pre, syn])\n",
    "        return w_new\n",
    "\n",
    "    def update_weights(self):\n",
    "        for bio in range(self.n_bio):\n",
    "            for pre in range(self.n_pre):\n",
    "                for syn in range(self.n_syn):\n",
    "                    self.syn_weights[bio, pre, syn] = np.dot(self.d_pre[pre], self.syn_encoders[bio, pre, syn])\n",
    "        return self.syn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Readout Filter and Decoder Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_elephys(\n",
    "    save_data,\n",
    "    save_ensemble,\n",
    "    n_neurons,\n",
    "    tau_lpf,\n",
    "    n_zeros=1,\n",
    "    n_poles=3,\n",
    "    z_min=1e2,\n",
    "    z_max=1e3,\n",
    "    p_min=-1e2,\n",
    "    p_max=-1e0,\n",
    "    reg=0.1,\n",
    "    max_evals=200,\n",
    "    normalize=True,\n",
    "    seed=5):\n",
    "    \n",
    "    print \"running optimization ...\"\n",
    "    h_eps = []\n",
    "    hyps = {}  # hyperparameters\n",
    "    hyps['save_data'] = save_data\n",
    "    hyps['save_ensemble'] = save_ensemble\n",
    "    for bio in range(n_neurons):  # put all bios in one hyperparams so decoder act on all \n",
    "        for z in range(n_zeros):\n",
    "            hyps['%s_bio_%s_zero'%(bio, z)] = hp.uniform('%s_bio_%s_zero'%(bio, z), z_min, z_max)\n",
    "        for p in range(n_poles):\n",
    "            hyps['%s_bio_%s_pole'%(bio, p)] = hp.uniform('%s_bio_%s_pole'%(bio, p), p_min, p_max)\n",
    "\n",
    "\n",
    "    def objective(hyps):\n",
    "        from nengolib.signal import nrmse\n",
    "        from nengo.utils.numpy import rmse\n",
    "\n",
    "        for bio in range(n_neurons):\n",
    "            zeros = np.array([hyps['%s_bio_%s_zero'%(bio, z)] for z in range(n_zeros)])\n",
    "            poles = np.array([hyps['%s_bio_%s_pole'%(bio, p)] for p in range(n_poles)])\n",
    "            h_ep = LinearSystem((zeros, poles, 1.0))\n",
    "            if normalize:\n",
    "                h_ep/= h_ep.dcgain\n",
    "            h_eps.append(h_ep)\n",
    "                \n",
    "        spikes = np.load(hyps['save_data']+hyps['save_ensemble'])['spikes']\n",
    "        act_lpf = Lowpass(tau_lpf).filt(spikes)\n",
    "        act_eps = np.zeros_like(act_lpf)\n",
    "        for n in range(n_neurons):\n",
    "            act_eps[:,n] = h_eps[n].filt(act_lpf[:,n])\n",
    "        target = np.load(hyps['save_data']+\"target.npz\")['target']\n",
    "        if np.sum(act_eps != 0):\n",
    "            d_eps = nengo.solvers.LstsqL2(reg=reg)(act_eps, target)[0]\n",
    "        else:\n",
    "            d_eps = np.zeros((n_neurons, 1))\n",
    "        xhat_eps = np.dot(act_eps, d_eps)\n",
    "        if np.sum(target) != 0: nrmse = nrmse(xhat_eps, target=target)\n",
    "        else: nrmse = rmse(xhat_eps, target)\n",
    "\n",
    "        return {'loss': nrmse,\n",
    "            'h_eps': h_eps,\n",
    "            'd_eps': d_eps,\n",
    "            'status': STATUS_OK }\n",
    "\n",
    "    trials = Trials()\n",
    "\n",
    "    best = fmin(objective,\n",
    "                rstate=np.random.RandomState(seed=seed),\n",
    "                space=hyps,\n",
    "                algo=tpe.suggest,\n",
    "                max_evals=max_evals,\n",
    "                trials=trials)\n",
    "\n",
    "    best_idx = np.array(trials.losses()).argmin()\n",
    "    best_h_eps = trials.trials[best_idx]['result']['h_eps']\n",
    "    best_d_eps = trials.trials[best_idx]['result']['d_eps']\n",
    "\n",
    "    return best_h_eps, best_d_eps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kwargs(\n",
    "    n_neurons=10,\n",
    "    n_pre=100,\n",
    "    n_syn=1,\n",
    "    sec='tuft',\n",
    "    taus={'network': 0.05,\n",
    "          'readout': 0.05},\n",
    "    seeds={'ns': 1, 'ss':2, 'es': 3, 'cs': 4, 'ls': 5},\n",
    "    neuron_type=BahlNeuron(bias_method='weights_fixed')):\n",
    "    \n",
    "    pre_kwargs = dict(\n",
    "        n_neurons=n_pre,\n",
    "        dimensions=1,\n",
    "        max_rates=Uniform(20, 40),\n",
    "        seed=seeds['es'])\n",
    "    lif_kwargs = dict(\n",
    "        n_neurons=n_neurons,\n",
    "        dimensions=1,\n",
    "        max_rates=Uniform(20, 40),\n",
    "        neuron_type=nengo.LIFRate(),  # adaptiveLIF?\n",
    "        seed=seeds['es'],\n",
    "        label='lif')\n",
    "    conn_kwargs = dict(\n",
    "        sec=sec,\n",
    "        n_syn=n_syn,\n",
    "        syn_type='ExpSyn',\n",
    "        tau_list=[taus['network']],\n",
    "        synapse=taus['network'],\n",
    "        seed=seeds['cs'])\n",
    "    bio_kwargs = dict(\n",
    "        n_neurons=n_neurons,\n",
    "        dimensions=1,\n",
    "        encoders=Uniform(-1, 1),\n",
    "        gain=Uniform(0, 0),\n",
    "        bias=Uniform(0, 0),\n",
    "        neuron_type=neuron_type,\n",
    "        seed=seeds['es'],\n",
    "        label='bio')\n",
    "    \n",
    "    return pre_kwargs, lif_kwargs, conn_kwargs, bio_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_syn_encoders_init(\n",
    "    n_neurons=10,\n",
    "    n_pre=100,\n",
    "    n_syn=1,\n",
    "    signal='cos',\n",
    "    freq=1,\n",
    "    amp=1,\n",
    "    t=1.0,\n",
    "    sec='tuft',\n",
    "    taus={'network': 0.05,\n",
    "          'readout': 0.05},\n",
    "    seeds={'ns': 1, 'ss':2, 'es': 3, 'cs': 4, 'ls': 5},\n",
    "    T_u=1,\n",
    "    T_x=1):\n",
    "\n",
    "    norm, norm_s, norm_f = norms(signal, freq, amp, seeds['ss'], taus['network'], t)\n",
    "\n",
    "    pre_kwargs, lif_kwargs, conn_kwargs, bio_kwargs = get_kwargs(n_neurons, n_pre, n_syn, sec, taus, seeds)\n",
    "\n",
    "    # Build a network to collect encoders, gains, biases from target LIF\n",
    "    with nengo.Network(seed=seeds['ns']) as pre_model:\n",
    "        pre_u = nengo.Ensemble(radius=norm_s, **pre_kwargs)\n",
    "        pre_x = nengo.Ensemble(radius=norm, **pre_kwargs)\n",
    "        lif = nengo.Ensemble(**lif_kwargs)\n",
    "        pre_u_lif = nengo.Connection(pre_u, lif, transform=T_u, **conn_kwargs)\n",
    "        pre_x_lif = nengo.Connection(pre_x, lif, transform=T_x, **conn_kwargs)\n",
    "    sim = nengo.Simulator(pre_model, seed=seeds['ss'])\n",
    "    d_pre_u = sim.data[pre_u_lif].weights.T\n",
    "    d_pre_x = sim.data[pre_x_lif].weights.T\n",
    "    e_target = sim.data[lif].encoders\n",
    "    syn_encoders_pre_bio = np.zeros((n_neurons, n_pre, n_syn))\n",
    "    syn_encoders_bio_bio = np.zeros((n_neurons, n_neurons, n_syn))\n",
    "    for bio in range(n_neurons):\n",
    "        syn_encoders_pre_bio[bio] = e_target[bio] * np.ones((n_pre, n_syn))\n",
    "        syn_encoders_bio_bio[bio] = e_target[bio] * np.ones((n_neurons, n_syn))\n",
    "        \n",
    "    return syn_encoders_pre_bio, syn_encoders_bio_bio, d_pre_u, d_pre_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_decoders_filters(\n",
    "    save_dir,\n",
    "    d_pre_u,\n",
    "    d_pre_x,\n",
    "    d_eps_dict,\n",
    "    syn_weights_dict,\n",
    "    syn_encoders_dict,\n",
    "    h_eps_dict):\n",
    "    \n",
    "    print \"saving data ...\"\n",
    "    np.savez(save_dir+'decoders.npz',\n",
    "        d_pre_u=d_pre_u,\n",
    "        d_pre_x=d_pre_x,    \n",
    "        d_eps_bio=d_eps_dict['d_eps_bio'],\n",
    "        d_eps_supv=d_eps_dict['d_eps_supv'])\n",
    "\n",
    "    np.savez(save_dir+'syn_weights.npz',\n",
    "        syn_weights_pre_u_supv=syn_weights_dict['syn_weights_pre_u_supv'],\n",
    "        syn_weights_pre_x_supv=syn_weights_dict['syn_weights_pre_x_supv'],\n",
    "        syn_weights_pre_u_bio=syn_weights_dict['syn_weights_pre_u_bio'],\n",
    "        syn_weights_supv_bio=syn_weights_dict['syn_weights_supv_bio'],\n",
    "        syn_weights_bio_bio=syn_weights_dict['syn_weights_bio_bio'])\n",
    "\n",
    "    np.savez(save_dir+'syn_encoders.npz',\n",
    "        syn_encoders_pre_u_supv=syn_encoders_dict['syn_encoders_pre_u_supv'],\n",
    "        syn_encoders_pre_x_supv=syn_encoders_dict['syn_encoders_pre_x_supv'],\n",
    "        syn_encoders_pre_u_bio=syn_encoders_dict['syn_encoders_pre_u_bio'],\n",
    "        syn_encoders_supv_bio=syn_encoders_dict['syn_encoders_supv_bio'],\n",
    "        syn_encoders_bio_bio=syn_encoders_dict['syn_encoders_bio_bio'])\n",
    "\n",
    "    h_eps_bio_num = [np.array(filt.num) for filt in h_eps_dict['h_eps_bio']]\n",
    "    h_eps_bio_den = [np.array(filt.den) for filt in h_eps_dict['h_eps_bio']]\n",
    "    h_eps_supv_num = [np.array(filt.num) for filt in h_eps_dict['h_eps_supv']]\n",
    "    h_eps_supv_den = [np.array(filt.den) for filt in h_eps_dict['h_eps_supv']]\n",
    "\n",
    "    np.savez(save_dir+'filters.npz',\n",
    "        h_eps_bio_num=h_eps_bio_num,\n",
    "        h_eps_bio_den=h_eps_bio_den,\n",
    "        h_eps_supv_num=h_eps_supv_num,\n",
    "        h_eps_supv_den=h_eps_supv_den)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_decoders_filters(save_dir):\n",
    "    \n",
    "    d_pre_u = np.load(save_dir+'decoders.npz')['d_pre_u']\n",
    "    d_pre_x = np.load(save_dir+'decoders.npz')['d_pre_x']\n",
    "\n",
    "    d_eps_bio = np.load(save_dir+'decoders.npz')['d_eps_bio']\n",
    "    d_eps_supv = np.load(save_dir+'decoders.npz')['d_eps_supv']\n",
    "    d_eps_dict_fb = {'d_eps_bio': d_eps_bio, 'd_eps_supv': d_eps_supv}\n",
    "\n",
    "    syn_weights_pre_u_supv = np.load(save_dir+'syn_weights.npz')['syn_weights_pre_u_supv']\n",
    "    syn_weights_pre_x_supv = np.load(save_dir+'syn_weights.npz')['syn_weights_pre_x_supv']\n",
    "    syn_weights_pre_u_bio = np.load(save_dir+'syn_weights.npz')['syn_weights_pre_u_bio']\n",
    "    syn_weights_supv_bio = np.load(save_dir+'syn_weights.npz')['syn_weights_supv_bio']\n",
    "    syn_weights_bio_bio = np.load(save_dir+'syn_weights.npz')['syn_weights_bio_bio']\n",
    "    syn_weights_dict_fb = {\n",
    "        'syn_weights_pre_u_supv': syn_weights_pre_u_supv,\n",
    "        'syn_weights_pre_x_supv': syn_weights_pre_x_supv,\n",
    "        'syn_weights_pre_u_bio': syn_weights_pre_u_bio,\n",
    "        'syn_weights_supv_bio': syn_weights_supv_bio,\n",
    "        'syn_weights_bio_bio': syn_weights_bio_bio,\n",
    "    }\n",
    "\n",
    "    syn_encoders_pre_u_supv = np.load(save_dir+'syn_encoders.npz')['syn_encoders_pre_u_supv']\n",
    "    syn_encoders_pre_x_supv = np.load(save_dir+'syn_encoders.npz')['syn_encoders_pre_x_supv']\n",
    "    syn_encoders_pre_u_bio = np.load(save_dir+'syn_encoders.npz')['syn_encoders_pre_u_bio']\n",
    "    syn_encoders_supv_bio = np.load(save_dir+'syn_encoders.npz')['syn_encoders_supv_bio']\n",
    "    syn_encoders_bio_bio = np.load(save_dir+'syn_encoders.npz')['syn_encoders_bio_bio']\n",
    "    syn_encoders_dict_fb = {\n",
    "        'syn_encoders_pre_u_supv': syn_encoders_pre_u_supv,\n",
    "        'syn_encoders_pre_x_supv': syn_encoders_pre_x_supv,\n",
    "        'syn_encoders_pre_u_bio': syn_encoders_pre_u_bio,\n",
    "        'syn_encoders_supv_bio': syn_encoders_supv_bio,\n",
    "        'syn_encoders_bio_bio': syn_encoders_bio_bio,\n",
    "    }\n",
    "    \n",
    "    h_eps_bio_num = np.load(save_dir+'filters.npz')['h_eps_bio_num']\n",
    "    h_eps_bio_den = np.load(save_dir+'filters.npz')['h_eps_bio_den']\n",
    "    h_eps_supv_num = np.load(save_dir+'filters.npz')['h_eps_supv_num']\n",
    "    h_eps_supv_den = np.load(save_dir+'filters.npz')['h_eps_supv_den']\n",
    "    h_eps_bio = [LinearSystem((h_eps_bio_num[i], h_eps_bio_den[i])) for i in range(len(h_eps_bio_num))]\n",
    "    h_eps_supv = [LinearSystem((h_eps_supv_num[i], h_eps_supv_den[i])) for i in range(len(h_eps_supv_num))]\n",
    "    h_eps_dict_fb = {'h_eps_bio': h_eps_bio, 'h_eps_supv': h_eps_supv}\n",
    "\n",
    "    \n",
    "    return d_pre_u, d_pre_x, d_eps_dict, syn_weights_dict_fb, syn_encoders_dict_fb, h_eps_dict_fb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_optimize_alternate(\n",
    "    d_pre_u,\n",
    "    d_pre_x,    \n",
    "    d_eps_bio,\n",
    "    d_eps_supv,\n",
    "    h_eps_bio,\n",
    "    h_eps_supv,\n",
    "    syn_encoders_pre_u_supv,\n",
    "    syn_encoders_pre_x_supv,\n",
    "    syn_encoders_pre_u_bio,\n",
    "    syn_encoders_supv_bio,\n",
    "    syn_encoders_bio_bio,\n",
    "    syn_weights_pre_u_supv,\n",
    "    syn_weights_pre_x_supv,\n",
    "    syn_weights_pre_u_bio,\n",
    "    syn_weights_supv_bio,\n",
    "    syn_weights_bio_bio,\n",
    "    t=1,\n",
    "    n_neurons=100,\n",
    "    n_neurons_plot=10,\n",
    "    n_pre=100,\n",
    "    n_syn=1,\n",
    "    signal='cos',\n",
    "    freq=1,\n",
    "    amp=1,\n",
    "    sec='tuft',\n",
    "    taus={'network': 0.05,\n",
    "          'readout': 0.05},\n",
    "    regs={'pre-bio': 0.1,\n",
    "          'bio-out': 0.1},\n",
    "    seeds={'ns': 1, 'ss':2, 'es': 3, 'cs': 4, 'ls': 5},\n",
    "    neuron_type=BahlNeuron(bias_method='weights_fixed'),\n",
    "    save_dir='/home/pduggins/nengo_bioneurons/nengo_bioneurons/tests/data/double_optimize_alternate/',\n",
    "    save_suffix='default/',\n",
    "    eta=0,\n",
    "    learn_pre_supv=False,\n",
    "    learn_supv_bio=False,\n",
    "    learn_bio_bio=False,\n",
    "    optimize_supv=False,\n",
    "    optimize_bio=False,\n",
    "    plot_supv=False,\n",
    "    plot_bio=False,\n",
    "    sim_supv=False,\n",
    "    sim_bio=False,\n",
    "    save_df=True):\n",
    "    \n",
    "    if not os.path.exists(save_dir+save_suffix):\n",
    "        os.makedirs(save_dir+save_suffix)\n",
    "    \n",
    "    # transform input signal u so that the integral x is normalized to np.max(x)==1\n",
    "    norm, norm_s, norm_f = norms(signal, freq, amp, seeds['ss'], taus['network'], t)\n",
    "    # keyword arguments for ensembles and connections\n",
    "    pre_kwargs, lif_kwargs, conn_kwargs, bio_kwargs = get_kwargs(\n",
    "        n_neurons, n_pre, n_syn, sec, taus, seeds, neuron_type)\n",
    "    \n",
    "    # Simulate the full network with encoder learning rules. Skip simulating supv or bio when possible.\n",
    "    with nengo.Network(seed=seeds['ns']) as model:\n",
    "        u = make_stimulus(signal, freq, amp, seed=seeds['ss'])\n",
    "        pre_u = nengo.Ensemble(radius=norm_s, **pre_kwargs)\n",
    "        pre_x = nengo.Ensemble(radius=norm, **pre_kwargs)\n",
    "        if sim_supv: supv = nengo.Ensemble(**bio_kwargs)\n",
    "        if sim_bio: bio = nengo.Ensemble(**bio_kwargs)\n",
    "        lif = nengo.Ensemble(**lif_kwargs)\n",
    "        tar = nengo.Ensemble(1, 1, neuron_type=nengo.Direct())\n",
    "\n",
    "        # normal connections\n",
    "        nengo.Connection(u, pre_u, synapse=None, seed=seeds['cs'])\n",
    "        nengo.Connection(u, pre_x, synapse=1/s, seed=seeds['cs'])\n",
    "        nengo.Connection(u, tar, synapse=1/s, transform=1.0/norm_f)\n",
    "        nengo.Connection(pre_u, lif, synapse=taus['network'], transform=taus['network']/norm_f)\n",
    "        nengo.Connection(pre_x, lif, synapse=taus['network'], transform=1.0/norm_f)  # proxy for accuracy\n",
    "#         lif_lif = nengo.Connection(lif, lif, **conn_kwargs)  # true recurrence on training spikes\n",
    "        \n",
    "        # bioneuron connections (learned)\n",
    "        if sim_supv:\n",
    "            pre_u_supv = nengo.Connection(pre_u, supv, syn_weights=syn_weights_pre_u_supv, **conn_kwargs)\n",
    "            pre_x_supv = nengo.Connection(pre_x, supv, syn_weights=syn_weights_pre_x_supv, **conn_kwargs)\n",
    "        if sim_bio:\n",
    "            pre_u_bio = nengo.Connection(pre_u, bio, syn_weights=syn_weights_pre_u_bio, **conn_kwargs)\n",
    "            bio_bio = nengo.Connection(bio, bio, syn_weights=syn_weights_bio_bio, **conn_kwargs)\n",
    "        if sim_supv and sim_bio:\n",
    "            supv_bio = nengo.Connection(supv, bio, syn_weights=syn_weights_supv_bio, **conn_kwargs)\n",
    "  \n",
    "        # associate encoder learning nodes with each learned connection\n",
    "        if learn_pre_supv and sim_supv:\n",
    "            enc_node_pre_u_supv = EncoderNode(\n",
    "                pre_u_supv, n_neurons, n_syn, 1, d_pre_u, eta, seeds['ls'], syn_encoders_pre_u_supv)\n",
    "            pre_u_supv.learning_node = enc_node_pre_u_supv\n",
    "            nengo.Connection(supv.neurons, enc_node_pre_u_supv[0:n_neurons], synapse=taus['readout'])\n",
    "            nengo.Connection(lif.neurons, enc_node_pre_u_supv[n_neurons:2*n_neurons], synapse=taus['readout'])\n",
    "\n",
    "            enc_node_pre_x_supv = EncoderNode(\n",
    "                pre_x_supv, n_neurons, n_syn, 1, d_pre_x, eta, seeds['ls'], syn_encoders_pre_x_supv)\n",
    "            pre_x_supv.learning_node = enc_node_pre_x_supv\n",
    "            nengo.Connection(supv.neurons, enc_node_pre_x_supv[0:n_neurons], synapse=taus['readout'])\n",
    "            nengo.Connection(lif.neurons, enc_node_pre_x_supv[n_neurons:2*n_neurons], synapse=taus['readout'])\n",
    "            \n",
    "        if learn_supv_bio and sim_supv and sim_bio:\n",
    "            enc_node_pre_u_bio = EncoderNode(\n",
    "                pre_u_bio, n_neurons, n_syn, 1, d_pre_u, eta, seeds['ls'], syn_encoders_pre_u_bio)\n",
    "            pre_u_bio.learning_node = enc_node_pre_u_bio\n",
    "            nengo.Connection(bio.neurons, enc_node_pre_u_bio[0:n_neurons], synapse=taus['readout'])\n",
    "            nengo.Connection(lif.neurons, enc_node_pre_u_bio[n_neurons:2*n_neurons], synapse=taus['readout'])\n",
    "\n",
    "            enc_node_supv_bio = EncoderNode(\n",
    "                supv_bio, n_neurons, n_syn, 1, d_eps_supv, eta, seeds['ls'], syn_encoders_supv_bio)\n",
    "            supv_bio.learning_node = enc_node_supv_bio\n",
    "            nengo.Connection(bio.neurons, enc_node_supv_bio[0:n_neurons], synapse=taus['readout'])\n",
    "            nengo.Connection(lif.neurons, enc_node_supv_bio[n_neurons:2*n_neurons], synapse=taus['readout'])\n",
    "            \n",
    "        if learn_bio_bio and sim_bio:\n",
    "            enc_node_bio_bio = EncoderNode(\n",
    "                bio_bio, n_neurons, n_syn, 1, d_eps_bio, eta, seeds['ls'], syn_encoders_bio_bio)\n",
    "            bio_bio.learning_node = enc_node_bio_bio\n",
    "            nengo.Connection(bio.neurons, enc_node_bio_bio[0:n_neurons], synapse=taus['readout'])\n",
    "            nengo.Connection(lif.neurons, enc_node_bio_bio[n_neurons:2*n_neurons], synapse=taus['readout'])\n",
    "\n",
    "        # probes\n",
    "        p_stim = nengo.Probe(u, synapse=None)\n",
    "        p_target = nengo.Probe(tar, synapse=None)\n",
    "        if sim_supv:\n",
    "            p_spk_supv = nengo.Probe(supv.neurons, synapse=None)\n",
    "            p_act_supv = nengo.Probe(supv.neurons, synapse=taus['readout'])\n",
    "        if sim_bio:\n",
    "            p_spk_bio = nengo.Probe(bio.neurons, synapse=None)\n",
    "            p_act_bio = nengo.Probe(bio.neurons, synapse=taus['readout'])\n",
    "        p_act_lif = nengo.Probe(lif.neurons, synapse=taus['readout'])\n",
    "        p_lif = nengo.Probe(lif, synapse=taus['readout'])\n",
    "\n",
    "    # RUN the simulation\n",
    "    with nengo.Simulator(model, seed=seeds['ss']) as sim:\n",
    "        sim.run(t)\n",
    "\n",
    "    # collect spikes, lowpass activities, and lif decodes\n",
    "    lpf = Lowpass(taus['readout'])\n",
    "    stim = lpf.filt(sim.data[p_stim])\n",
    "    target = lpf.filt(sim.data[p_target])\n",
    "    if sim_supv:\n",
    "        spikes_supv = sim.data[p_spk_supv]\n",
    "        act_lpf_supv = sim.data[p_act_supv]\n",
    "        np.savez(save_dir+save_suffix+\"spikes_supv.npz\", spikes=spikes_supv)\n",
    "    if sim_bio:\n",
    "        spikes_bio = sim.data[p_spk_bio]\n",
    "        act_lpf_bio = sim.data[p_act_bio]\n",
    "        np.savez(save_dir+save_suffix+\"spikes_bio.npz\", spikes=spikes_bio)\n",
    "    act_lif = sim.data[p_act_lif]\n",
    "    xhat_lif = sim.data[p_lif]\n",
    "    nrmse_lif = nrmse(xhat_lif, target=target)\n",
    "    np.savez(save_dir+save_suffix+\"target.npz\", target=target)\n",
    "    np.savez(save_dir+save_suffix+\"lif.npz\", act=act_lif, xhat=xhat_lif)\n",
    "    \n",
    "    # optimize d_eps and h_eps given spikes and a target\n",
    "    if optimize_supv:\n",
    "        h_eps_supv, d_eps_supv = optimize_elephys(\n",
    "            save_dir+save_suffix,\n",
    "            \"spikes_supv.npz\",\n",
    "            n_neurons,\n",
    "            taus['readout'],\n",
    "            normalize=True,\n",
    "            seed=seeds['ls'])\n",
    "        \n",
    "    if optimize_bio:\n",
    "        h_eps_bio, d_eps_bio = optimize_elephys(\n",
    "            save_dir+save_suffix,\n",
    "            \"spikes_bio.npz\",\n",
    "            n_neurons,\n",
    "            taus['readout'],\n",
    "            normalize=True,\n",
    "            seed=seeds['ls'])\n",
    "\n",
    "    # Compute activities and xhat from h_eps and d_eps, then bin data for tuning curve estimation\n",
    "    act_eps_supv = np.zeros_like(act_lif)\n",
    "    act_eps_bio = np.zeros_like(act_lif)\n",
    "    x_bins_lif, hz_means_lif, hz_stds_lif = bin_activities_values_1d(\n",
    "        target, act_lif, n_neurons=n_neurons)\n",
    "    if sim_supv:\n",
    "        for n in range(n_neurons):\n",
    "            act_eps_supv[:,n] = h_eps_supv[n].filt(act_lpf_supv[:,n])\n",
    "        xhat_eps_supv = np.dot(act_eps_supv, d_eps_supv)\n",
    "        nrmse_eps_supv = nrmse(xhat_eps_supv, target=target)\n",
    "        x_bins_eps_supv, hz_means_eps_supv, hz_stds_eps_supv = bin_activities_values_1d(\n",
    "            target, act_eps_supv, n_neurons=n_neurons)\n",
    "        np.savez(save_dir+save_suffix+\"supv.npz\", act=act_eps_supv, xhat=xhat_eps_supv)\n",
    "        \n",
    "    if sim_bio:\n",
    "        for n in range(n_neurons):\n",
    "            act_eps_bio[:,n] = h_eps_bio[n].filt(act_lpf_bio[:,n])\n",
    "        xhat_eps_bio = np.dot(act_eps_bio, d_eps_bio)\n",
    "        nrmse_eps_bio = nrmse(xhat_eps_bio, target=target)\n",
    "        x_bins_eps_bio, hz_means_eps_bio, hz_stds_eps_bio = bin_activities_values_1d(\n",
    "            target, act_eps_bio, n_neurons=n_neurons)\n",
    "        np.savez(save_dir+save_suffix+\"bio.npz\", act=act_eps_bio, xhat=xhat_eps_bio)\n",
    "\n",
    "    # Update synaptic encoders and weights for any connection that has been learned\n",
    "    if learn_pre_supv:\n",
    "        syn_encoders_pre_u_supv_new = enc_node_pre_u_supv.syn_encoders\n",
    "        syn_encoders_pre_x_supv_new = enc_node_pre_x_supv.syn_encoders\n",
    "        syn_weights_pre_u_supv_new = sim.data[pre_u_supv].weights\n",
    "        syn_weights_pre_x_supv_new = sim.data[pre_x_supv].weights\n",
    "    else:\n",
    "        syn_encoders_pre_u_supv_new = syn_encoders_pre_u_supv\n",
    "        syn_encoders_pre_x_supv_new = syn_encoders_pre_x_supv\n",
    "        syn_weights_pre_u_supv_new = syn_weights_pre_u_supv\n",
    "        syn_weights_pre_x_supv_new = syn_weights_pre_x_supv\n",
    "    if learn_supv_bio:\n",
    "        syn_encoders_pre_u_bio_new = enc_node_pre_u_bio.syn_encoders\n",
    "        syn_encoders_supv_bio_new = enc_node_supv_bio.syn_encoders\n",
    "        syn_weights_pre_u_bio_new = sim.data[pre_u_bio].weights\n",
    "        syn_weights_supv_bio_new = sim.data[supv_bio].weights\n",
    "    else:\n",
    "        syn_encoders_pre_u_bio_new = syn_encoders_pre_u_bio\n",
    "        syn_encoders_supv_bio_new = syn_encoders_supv_bio\n",
    "        syn_weights_pre_u_bio_new = syn_weights_pre_u_bio\n",
    "        syn_weights_supv_bio_new = syn_weights_supv_bio\n",
    "    if learn_bio_bio:\n",
    "        syn_encoders_bio_bio_new = enc_node_bio_bio.syn_encoders\n",
    "        syn_weights_bio_bio_new = sim.data[bio_bio].weights\n",
    "    else:\n",
    "        syn_encoders_bio_bio_new = syn_encoders_bio_bio\n",
    "        syn_weights_bio_bio_new = syn_weights_bio_bio\n",
    "    \n",
    "    # Save dictionary of filters, decoders, encoders, and weights\n",
    "    h_eps_new = {'h_eps_supv': h_eps_supv, 'h_eps_bio': h_eps_bio}\n",
    "    d_eps_new = {'d_eps_supv': d_eps_supv, 'd_eps_bio': d_eps_bio}\n",
    "    syn_encoders_new = {\n",
    "        'syn_encoders_pre_u_supv': syn_encoders_pre_u_supv_new,\n",
    "        'syn_encoders_pre_x_supv': syn_encoders_pre_x_supv_new,\n",
    "        'syn_encoders_pre_u_bio': syn_encoders_pre_u_bio_new,\n",
    "        'syn_encoders_supv_bio': syn_encoders_supv_bio_new,\n",
    "        'syn_encoders_bio_bio': syn_encoders_bio_bio_new,\n",
    "        }\n",
    "    syn_weights_new = {\n",
    "        'syn_weights_pre_u_supv': syn_weights_pre_u_supv_new,\n",
    "        'syn_weights_pre_x_supv': syn_weights_pre_x_supv_new,\n",
    "        'syn_weights_pre_u_bio': syn_weights_pre_u_bio_new,\n",
    "        'syn_weights_supv_bio': syn_weights_supv_bio_new,\n",
    "        'syn_weights_bio_bio': syn_weights_bio_bio_new,\n",
    "        }\n",
    "    if save_df:\n",
    "        save_decoders_filters(save_dir+save_suffix,\n",
    "            d_pre_u, d_pre_x, d_eps_new, syn_weights_new, syn_encoders_new, h_eps_new)\n",
    "    \n",
    "    # Plots\n",
    "    if plot_supv and sim_supv:\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 8))\n",
    "        rasterplot(sim.trange(), spikes_supv, ax=ax1)\n",
    "        ax1.set(xlabel='time', ylabel='neuron')\n",
    "        sns.distplot(np.ravel(act_lpf_supv), ax=ax2)\n",
    "        ax2.set(xlim=((1, 50)), ylim=((0, 0.05)), xlabel='activity', ylabel='frequency', title='supv')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        times = np.arange(0, 1, 0.001)\n",
    "        fig, (ax, ax2, ax3) = plt.subplots(1, 3, figsize=(12, 4))\n",
    "        ax.plot(times, Lowpass(taus['readout']).impulse(len(times)))\n",
    "        for n in range(n_neurons):\n",
    "            ax2.plot(times, h_eps_supv[n].impulse(len(times)))\n",
    "            ax3.plot(times, h_eps_supv[n].filt(Lowpass(taus['readout']).impulse(len(times))))\n",
    "        ax.set(xlabel='time', ylabel='amplitude', title='lowpass')\n",
    "        ax2.set(xlabel='time', title='h_eps_supv')\n",
    "        ax3.set(xlabel='time', title='h_eps_supv.filt(lowpass)')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        cmap = sns.color_palette('hls', n_neurons)\n",
    "        fig, (ax4, ax5) = plt.subplots(1, 2, figsize=(8, 8), sharey=True)\n",
    "        for n in range(n_neurons):\n",
    "            ax4.plot(x_bins_lif, hz_means_lif[n], c=cmap[n])\n",
    "            ax4.fill_between(x_bins_lif,\n",
    "                hz_means_lif[n]+hz_stds_lif[n],\n",
    "                hz_means_lif[n]-hz_stds_lif[n],\n",
    "                alpha=0.5, facecolor=cmap[n])\n",
    "            ax5.plot(x_bins_eps_supv, hz_means_eps_supv[n], c=cmap[n])\n",
    "            ax5.fill_between(x_bins_eps_supv,\n",
    "                hz_means_eps_supv[n]+hz_stds_eps_supv[n],\n",
    "                hz_means_eps_supv[n]-hz_stds_eps_supv[n],\n",
    "                alpha=0.5, facecolor=cmap[n])\n",
    "        ax4.set(xlim=((-1,1)), ylim=((0, 50)), xlabel='$\\mathbf{x}$', ylabel='activity (Hz)', title='lif')\n",
    "        ax5.set(xlim=((-1,1)), ylim=((0, 50)), xlabel='$\\mathbf{x}$', title='elephys supv')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        fig, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
    "        ax.plot(sim.trange(), target, label='target', linestyle='--')\n",
    "        ax.plot(sim.trange(), xhat_lif, alpha=0.5, label='lif, nrmse=%.3f' %nrmse_lif)\n",
    "        ax.plot(sim.trange(), xhat_eps_supv, alpha=0.5, label='elephys, nrmse=%.3f' %nrmse_eps_supv)\n",
    "        ax.set(xlabel='time', ylabel='$\\mathbf{x}$', title='supv')\n",
    "        ax.legend(loc='lower left')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "    if plot_bio and sim_bio:\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 8))\n",
    "        rasterplot(sim.trange(), spikes_bio, ax=ax1)\n",
    "        ax1.set(xlabel='time', ylabel='neuron')\n",
    "        sns.distplot(np.ravel(act_lpf_bio), ax=ax2)\n",
    "        ax2.set(xlim=((1, 50)), ylim=((0, 0.05)), xlabel='activity', ylabel='frequency', title='bio')\n",
    "        \n",
    "        times = np.arange(0, 1, 0.001)\n",
    "        fig, (ax, ax2, ax3) = plt.subplots(1, 3, figsize=(12, 4))\n",
    "        ax.plot(times, Lowpass(taus['readout']).impulse(len(times)))\n",
    "        for n in range(n_neurons):\n",
    "            ax2.plot(times, h_eps_bio[n].impulse(len(times)))\n",
    "            ax3.plot(times, h_eps_bio[n].filt(Lowpass(taus['readout']).impulse(len(times))))\n",
    "        ax.set(xlabel='time', ylabel='amplitude', title='lowpass')\n",
    "        ax2.set(xlabel='time', title='h_eps_bio')\n",
    "        ax3.set(xlabel='time', title='h_eps_bio.filt(lowpass)')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        cmap = sns.color_palette('hls', n_neurons_plot)\n",
    "        fig, (ax4, ax5) = plt.subplots(1, 2, figsize=(8, 8), sharey=True)\n",
    "        for n in range(n_neurons_plot):\n",
    "            ax4.plot(x_bins_lif, hz_means_lif[n], c=cmap[n])\n",
    "            ax4.fill_between(x_bins_lif,\n",
    "                hz_means_lif[n]+hz_stds_lif[n],\n",
    "                hz_means_lif[n]-hz_stds_lif[n],\n",
    "                alpha=0.5, facecolor=cmap[n])\n",
    "            ax5.plot(x_bins_eps_bio, hz_means_eps_bio[n], c=cmap[n])\n",
    "            ax5.fill_between(x_bins_eps_bio,\n",
    "                hz_means_eps_bio[n]+hz_stds_eps_bio[n],\n",
    "                hz_means_eps_bio[n]-hz_stds_eps_bio[n],\n",
    "                alpha=0.5, facecolor=cmap[n])\n",
    "        ax4.set(xlim=((-1,1)), ylim=((0, 50)), xlabel='$\\mathbf{x}$', ylabel='activity (Hz)', title='lif')\n",
    "        ax5.set(xlim=((-1,1)), ylim=((0, 50)), xlabel='$\\mathbf{x}$', title='elephys bio')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        fig, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
    "        ax.plot(sim.trange(), target, label='target', linestyle='--')\n",
    "        ax.plot(sim.trange(), xhat_lif, alpha=0.5, label='lif, nrmse=%.3f' %nrmse_lif)\n",
    "        ax.plot(sim.trange(), xhat_eps_bio, alpha=0.5, label='elephys, nrmse=%.3f' %nrmse_eps_bio)\n",
    "        ax.set(xlabel='time', ylabel='$\\mathbf{x}$', title='bio')\n",
    "        ax.legend(loc='lower left')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "    return d_eps_new, h_eps_new, syn_encoders_new, syn_weights_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neurons = 100\n",
    "n_pre = 100\n",
    "max_evals = 100\n",
    "n_syn = 1\n",
    "freq = 1\n",
    "taus = {'network': 0.05, 'readout': 0.05}\n",
    "eta = 5e-5\n",
    "\n",
    "t_pre_supv = 16*np.pi\n",
    "t_supv_bio = 16*np.pi\n",
    "t_bio_bio = 16*np.pi\n",
    "t_cos = 4*np.pi\n",
    "t_white_noise = 4*np.pi\n",
    "signal = 'cos'\n",
    "\n",
    "save_dir='/home/pduggins/nengo_bioneurons/nengo_bioneurons/tests/data/double_optimize_alternate/%s_neurons_%s_evals_%s_nsyn_%.3f_freq_%s_eta_%s_signal/' %(n_neurons, max_evals, n_syn, freq, eta, signal)\n",
    "     \n",
    "d_eps_bio = np.zeros((n_neurons, 1))\n",
    "d_eps_supv = np.zeros((n_neurons, 1))\n",
    "\n",
    "h_eps_bio = [Lowpass(taus['readout']) for _ in range(n_neurons)]\n",
    "h_eps_supv = [Lowpass(taus['readout']) for _ in range(n_neurons)]\n",
    "\n",
    "syn_encoders_pre_bio, syn_encoders_bio_bio, d_pre_u, d_pre_x = get_syn_encoders_init(\n",
    "    n_neurons, n_pre, n_syn, t=t_pre_supv, freq=freq, T_u=0.1, T_x=1.0)\n",
    "syn_encoders_pre_u_supv = syn_encoders_pre_bio\n",
    "syn_encoders_pre_x_supv = syn_encoders_pre_bio\n",
    "syn_encoders_pre_u_bio = syn_encoders_pre_bio\n",
    "syn_encoders_supv_bio = syn_encoders_bio_bio\n",
    "syn_encoders_bio_bio = syn_encoders_bio_bio\n",
    "\n",
    "syn_weights_pre_u_supv = np.zeros((n_neurons, n_pre, n_syn))\n",
    "syn_weights_pre_x_supv = np.zeros((n_neurons, n_pre, n_syn))\n",
    "syn_weights_pre_u_bio = np.zeros((n_neurons, n_pre, n_syn))\n",
    "syn_weights_supv_bio = np.zeros((n_neurons, n_neurons, n_syn))\n",
    "syn_weights_bio_bio = np.zeros((n_neurons, n_neurons, n_syn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Training syn_encoders for pre_u_supv and pre_x_supv ...\"\n",
    "_, _, syn_encoders_dict_new, syn_weights_dict_new = double_optimize_alternate(\n",
    "    d_pre_u,\n",
    "    d_pre_x,    \n",
    "    d_eps_bio,\n",
    "    d_eps_supv,\n",
    "    h_eps_bio,\n",
    "    h_eps_supv,\n",
    "    syn_encoders_pre_u_supv,\n",
    "    syn_encoders_pre_x_supv,\n",
    "    syn_encoders_pre_u_bio,\n",
    "    syn_encoders_supv_bio,\n",
    "    syn_encoders_bio_bio,\n",
    "    syn_weights_pre_u_supv,\n",
    "    syn_weights_pre_x_supv,\n",
    "    syn_weights_pre_u_bio,\n",
    "    syn_weights_supv_bio,\n",
    "    syn_weights_bio_bio,\n",
    "    t=t_pre_supv,\n",
    "    signal=signal,\n",
    "    freq=freq,\n",
    "    n_neurons=n_neurons,\n",
    "    n_syn=n_syn,\n",
    "    save_dir=save_dir,\n",
    "    save_suffix=\"syn_enc_supv/\",\n",
    "    eta=eta,\n",
    "    learn_pre_supv=True,\n",
    "    learn_supv_bio=False,\n",
    "    learn_bio_bio=False,\n",
    "    optimize_supv=False,\n",
    "    optimize_bio=False,\n",
    "    plot_supv=True,\n",
    "    plot_bio=False,\n",
    "    sim_supv=True,\n",
    "    sim_bio=False)\n",
    "syn_weights_pre_u_supv = syn_weights_dict_new['syn_weights_pre_u_supv']\n",
    "syn_weights_pre_x_supv = syn_weights_dict_new['syn_weights_pre_x_supv']\n",
    "syn_encoders_pre_u_supv = syn_encoders_dict_new['syn_encoders_pre_u_supv']\n",
    "syn_encoders_pre_x_supv = syn_encoders_dict_new['syn_encoders_pre_x_supv']\n",
    "\n",
    "print \"Training d_eps/h_eps for supv ...\"\n",
    "d_eps_dict, h_eps_dict, _, _ = double_optimize_alternate(\n",
    "    d_pre_u,\n",
    "    d_pre_x,    \n",
    "    d_eps_bio,\n",
    "    d_eps_supv,\n",
    "    h_eps_bio,\n",
    "    h_eps_supv,\n",
    "    syn_encoders_pre_u_supv,\n",
    "    syn_encoders_pre_x_supv,\n",
    "    syn_encoders_pre_u_bio,\n",
    "    syn_encoders_supv_bio,\n",
    "    syn_encoders_bio_bio,\n",
    "    syn_weights_pre_u_supv,\n",
    "    syn_weights_pre_x_supv,\n",
    "    syn_weights_pre_u_bio,\n",
    "    syn_weights_supv_bio,\n",
    "    syn_weights_bio_bio,\n",
    "    t=t_pre_supv,\n",
    "    signal=signal,\n",
    "    freq=freq,\n",
    "    n_neurons=n_neurons,\n",
    "    n_syn=n_syn,\n",
    "    save_dir=save_dir,\n",
    "    save_suffix=\"d_eps_supv/\",\n",
    "    eta=eta,\n",
    "    learn_pre_supv=False,\n",
    "    learn_supv_bio=False,\n",
    "    learn_bio_bio=False,\n",
    "    optimize_supv=True,\n",
    "    optimize_bio=False,\n",
    "    plot_supv=True,\n",
    "    plot_bio=False,\n",
    "    sim_supv=True,\n",
    "    sim_bio=False)\n",
    "d_eps_supv = d_eps_dict['d_eps_supv']\n",
    "h_eps_supv = h_eps_dict['h_eps_supv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Training syn_encoders for pre_u_bio and supv_bio ...\"\n",
    "_, _, syn_encoders_dict_new, syn_weights_dict_new = double_optimize_alternate(\n",
    "    d_pre_u,\n",
    "    d_pre_x,    \n",
    "    d_eps_bio,\n",
    "    d_eps_supv,\n",
    "    h_eps_bio,\n",
    "    h_eps_supv,\n",
    "    syn_encoders_pre_u_supv,\n",
    "    syn_encoders_pre_x_supv,\n",
    "    syn_encoders_pre_u_bio,\n",
    "    syn_encoders_supv_bio,\n",
    "    syn_encoders_bio_bio,\n",
    "    syn_weights_pre_u_supv,\n",
    "    syn_weights_pre_x_supv,\n",
    "    syn_weights_pre_u_bio,\n",
    "    syn_weights_supv_bio,\n",
    "    syn_weights_bio_bio,\n",
    "    t=t_supv_bio,\n",
    "    signal=signal,\n",
    "    freq=freq,\n",
    "    n_neurons=n_neurons,\n",
    "    n_syn=n_syn,\n",
    "    save_dir=save_dir,\n",
    "    save_suffix=\"syn_enc_bio/\",\n",
    "    eta=eta,\n",
    "    learn_pre_supv=False,\n",
    "    learn_supv_bio=True,\n",
    "    learn_bio_bio=False,\n",
    "    optimize_supv=False,\n",
    "    optimize_bio=False,\n",
    "    plot_supv=False,\n",
    "    plot_bio=True,\n",
    "    sim_supv=True,\n",
    "    sim_bio=True)\n",
    "syn_weights_pre_u_bio = syn_weights_dict_new['syn_weights_pre_u_bio']\n",
    "syn_weights_supv_bio = syn_weights_dict_new['syn_weights_supv_bio']\n",
    "syn_encoders_pre_u_bio = syn_encoders_dict_new['syn_encoders_pre_u_bio']\n",
    "syn_encoders_supv_bio = syn_encoders_dict_new['syn_encoders_supv_bio']\n",
    "\n",
    "print \"Training d_eps/h_eps for bio ...\"\n",
    "d_eps_dict, h_eps_dict, _, _ = double_optimize_alternate(\n",
    "    d_pre_u,\n",
    "    d_pre_x,    \n",
    "    d_eps_bio,\n",
    "    d_eps_supv,\n",
    "    h_eps_bio,\n",
    "    h_eps_supv,\n",
    "    syn_encoders_pre_u_supv,\n",
    "    syn_encoders_pre_x_supv,\n",
    "    syn_encoders_pre_u_bio,\n",
    "    syn_encoders_supv_bio,\n",
    "    syn_encoders_bio_bio,\n",
    "    syn_weights_pre_u_supv,\n",
    "    syn_weights_pre_x_supv,\n",
    "    syn_weights_pre_u_bio,\n",
    "    syn_weights_supv_bio,\n",
    "    syn_weights_bio_bio,\n",
    "    t=t_supv_bio,\n",
    "    signal=signal,\n",
    "    freq=freq,\n",
    "    n_neurons=n_neurons,\n",
    "    n_syn=n_syn,\n",
    "    save_dir=save_dir,\n",
    "    save_suffix=\"d_eps_bio/\",\n",
    "    eta=eta,\n",
    "    learn_pre_supv=False,\n",
    "    learn_supv_bio=False,\n",
    "    learn_bio_bio=False,\n",
    "    optimize_supv=False,\n",
    "    optimize_bio=True,\n",
    "    plot_supv=False,\n",
    "    plot_bio=True,\n",
    "    sim_supv=True,\n",
    "    sim_bio=True)\n",
    "d_eps_bio = d_eps_dict['d_eps_bio']\n",
    "h_eps_bio = h_eps_dict['h_eps_bio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Training syn_encoders for bio_bio ...\"\n",
    "_, _, syn_encoders_dict_new, syn_weights_dict_new = double_optimize_alternate(\n",
    "    d_pre_u,\n",
    "    d_pre_x,    \n",
    "    d_eps_bio,\n",
    "    d_eps_supv,\n",
    "    h_eps_bio,\n",
    "    h_eps_supv,\n",
    "    syn_encoders_pre_u_supv,\n",
    "    syn_encoders_pre_x_supv,\n",
    "    syn_encoders_pre_u_bio,\n",
    "    syn_encoders_supv_bio,\n",
    "    syn_encoders_bio_bio,\n",
    "    syn_weights_pre_u_supv,\n",
    "    syn_weights_pre_x_supv,\n",
    "    syn_weights_pre_u_bio,\n",
    "    syn_weights_supv_bio,\n",
    "    syn_weights_bio_bio,\n",
    "    t=t_supv_bio,\n",
    "    signal=signal,\n",
    "    freq=freq,\n",
    "    n_neurons=n_neurons,\n",
    "    n_syn=n_syn,\n",
    "    save_dir=save_dir,\n",
    "    save_suffix=\"syn_enc_bio_bio/\",\n",
    "    eta=eta,\n",
    "    learn_pre_supv=False,\n",
    "    learn_supv_bio=False,\n",
    "    learn_bio_bio=True,\n",
    "    optimize_supv=False,\n",
    "    optimize_bio=False,\n",
    "    plot_supv=False,\n",
    "    plot_bio=True,\n",
    "    sim_supv=False,\n",
    "    sim_bio=True)\n",
    "syn_weights_bio_bio = syn_weights_dict_new['syn_weights_bio_bio']\n",
    "syn_encoders_bio_bio = syn_encoders_dict_new['syn_encoders_bio_bio']\n",
    "\n",
    "print \"Training d_eps/h_eps for bio again ...\"\n",
    "d_eps_dict, h_eps_dict, _, _ = double_optimize_alternate(\n",
    "    d_pre_u,\n",
    "    d_pre_x,    \n",
    "    d_eps_bio,\n",
    "    d_eps_supv,\n",
    "    h_eps_bio,\n",
    "    h_eps_supv,\n",
    "    syn_encoders_pre_u_supv,\n",
    "    syn_encoders_pre_x_supv,\n",
    "    syn_encoders_pre_u_bio,\n",
    "    syn_encoders_supv_bio,\n",
    "    syn_encoders_bio_bio,\n",
    "    syn_weights_pre_u_supv,\n",
    "    syn_weights_pre_x_supv,\n",
    "    syn_weights_pre_u_bio,\n",
    "    syn_weights_supv_bio,\n",
    "    syn_weights_bio_bio,\n",
    "    t=t_supv_bio,\n",
    "    signal=signal,\n",
    "    freq=freq,\n",
    "    n_neurons=n_neurons,\n",
    "    n_syn=n_syn,\n",
    "    save_dir=save_dir,\n",
    "    save_suffix=\"d_eps_bio/\",\n",
    "    eta=eta,\n",
    "    learn_pre_supv=False,\n",
    "    learn_supv_bio=False,\n",
    "    learn_bio_bio=False,\n",
    "    optimize_supv=False,\n",
    "    optimize_bio=True,\n",
    "    plot_supv=False,\n",
    "    plot_bio=True,\n",
    "    sim_supv=False,\n",
    "    sim_bio=True)\n",
    "d_eps_bio = d_eps_dict['d_eps_bio']\n",
    "h_eps_bio = h_eps_dict['h_eps_bio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Testing with sinusoid ...\"\n",
    "_, _, _, _ = double_optimize_alternate(\n",
    "    d_pre_u,\n",
    "    d_pre_x,    \n",
    "    d_eps_bio,\n",
    "    d_eps_supv,\n",
    "    h_eps_bio,\n",
    "    h_eps_supv,\n",
    "    syn_encoders_pre_u_supv,\n",
    "    syn_encoders_pre_x_supv,\n",
    "    syn_encoders_pre_u_bio,\n",
    "    syn_encoders_supv_bio,\n",
    "    syn_encoders_bio_bio,\n",
    "    syn_weights_pre_u_supv,\n",
    "    syn_weights_pre_x_supv,\n",
    "    syn_weights_pre_u_bio,\n",
    "    syn_weights_supv_bio,\n",
    "    syn_weights_bio_bio,\n",
    "    t=t_cos,\n",
    "    signal='cos',\n",
    "    freq=freq,\n",
    "    n_neurons=n_neurons,\n",
    "    n_syn=n_syn,\n",
    "    save_dir=save_dir,\n",
    "    save_suffix=\"test_cos/\",\n",
    "    eta=eta,\n",
    "    learn_pre_supv=False,\n",
    "    learn_supv_bio=False,\n",
    "    learn_bio_bio=False,\n",
    "    optimize_supv=False,\n",
    "    optimize_bio=False,\n",
    "    plot_supv=False,\n",
    "    plot_bio=True,\n",
    "    sim_supv=False,\n",
    "    sim_bio=True)\n",
    "\n",
    "print \"Testing with white noise ...\"\n",
    "_, _, _, _ = double_optimize_alternate(\n",
    "    d_pre_u,\n",
    "    d_pre_x,    \n",
    "    d_eps_bio,\n",
    "    d_eps_supv,\n",
    "    h_eps_bio,\n",
    "    h_eps_supv,\n",
    "    syn_encoders_pre_u_supv,\n",
    "    syn_encoders_pre_x_supv,\n",
    "    syn_encoders_pre_u_bio,\n",
    "    syn_encoders_supv_bio,\n",
    "    syn_encoders_bio_bio,\n",
    "    syn_weights_pre_u_supv,\n",
    "    syn_weights_pre_x_supv,\n",
    "    syn_weights_pre_u_bio,\n",
    "    syn_weights_supv_bio,\n",
    "    syn_weights_bio_bio,\n",
    "    t=t_white_noise,\n",
    "    signal='white_noise',\n",
    "    freq=freq,\n",
    "    n_neurons=n_neurons,\n",
    "    n_syn=n_syn,\n",
    "    save_dir=save_dir,\n",
    "    save_suffix=\"test_white_noise/\",\n",
    "    eta=eta,\n",
    "    learn_pre_supv=False,\n",
    "    learn_supv_bio=False,\n",
    "    learn_bio_bio=False,\n",
    "    optimize_supv=False,\n",
    "    optimize_bio=False,\n",
    "    plot_supv=False,\n",
    "    plot_bio=True,\n",
    "    sim_supv=False,\n",
    "    sim_bio=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
